{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/Video_Generation_Transformer/blob/master/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJz4WUwTnmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "import torchvision.models as models\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import re\n",
        "\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "from torch import autograd\n",
        "from torch.nn import functional as F\n",
        "import torch.nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "import torch.optim\n",
        "import torch.multiprocessing as mp\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaBLoPcRTnmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "from pathlib import Path\n",
        "# Suppose you are trying to load pre-trained resnet model in directory- models\\resnet\n",
        "\n",
        "os.environ['TORCH_HOME'] = 'D:\\dev\\Pytorch_Models\\models\\\\resnet' #setting the environment variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx72s-BGI0t6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c7285677-51e3-4189-86ff-645edaeead95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXmf7FSOMtC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "0d4a1ab8-a627-4d0d-898c-7a0933db72cd"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 134923 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.13-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLTnovF5Mxtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPMjsTt7Jabi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "5b630f59-234e-4d96-a5bf-b8afd8f20ecb"
      },
      "source": [
        "home =\"drive/dl_projects/Video_Genaeration/output\"\n",
        "home = Path(home)\n",
        "import tensorflow"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3vDQd5wJ-4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25adcca2-a740-4d93-bcd2-9552e1e0495f"
      },
      "source": [
        "!ls \"drive/dl_projects/Video_Genaeration/\""
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img.jpg  Model1  output  Pix2Pix.ipynb\tTransformer.ipynb  Video_Gen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLdnAS6ETnmi",
        "colab_type": "code",
        "outputId": "3c730d6d-3ef9-45e8-c18e-7faa0160fd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget --header=\"Host: www.cityscapes-dataset.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.cityscapes-dataset.com/downloads/\" --header=\"Cookie: PHPSESSID=4f0gk1d5hbc0ikttngvpm8ff52\" --header=\"Connection: keep-alive\" \"https://www.cityscapes-dataset.com/file-handling/?packageID=4\" -O \"leftImg8bit_trainextra.zip\" -c"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-20 22:13:22--  https://www.cityscapes-dataset.com/file-handling/?packageID=4\n",
            "Resolving www.cityscapes-dataset.com (www.cityscapes-dataset.com)... 139.19.217.8\n",
            "Connecting to www.cityscapes-dataset.com (www.cityscapes-dataset.com)|139.19.217.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47230218747 (44G) [application/octet-stream]\n",
            "Saving to: ‘leftImg8bit_trainextra.zip’\n",
            "\n",
            "leftImg8bit_trainex 100%[===================>]  43.99G  98.2MB/s    in 7m 26s  \n",
            "\n",
            "2019-11-20 22:20:53 (101 MB/s) - ‘leftImg8bit_trainextra.zip’ saved [47230218747/47230218747]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTndZBfHtTZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip leftImg8bit_trainextra.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riBpMJFiTnmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import json\n",
        "import os\n",
        "from collections import namedtuple\n",
        "import zipfile\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CityscapeDataset(Dataset):\n",
        "    \"\"\"`Cityscapes <http://www.cityscapes-dataset.com/>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where directory ``leftImg8bit``\n",
        "            \n",
        "        split (string, optional): The image split to use, ``train``, ``train_extra`` or ``val``\n",
        "       \n",
        "        transform (callable, optional): A function/transform that takes in a PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``  \n",
        "        transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
        "            and returns a transformed version.\n",
        "\n",
        "    Examples:\n",
        "\n",
        "      \n",
        "    \"\"\"\n",
        "\n",
        "    # Based on https://github.com/mcordts/cityscapesScripts\n",
        "  \n",
        "\n",
        "    def __init__(self, root=None, split='train_extra', transforms=None):\n",
        "        if root is not None:\n",
        "          self.images_dir = os.path.join(self.root, 'leftImg8bit', split)\n",
        "        else:\n",
        "          self.images_dir = os.path.join('leftImg8bit', split)\n",
        "        self.split = split\n",
        "        self.images = []\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "  \n",
        "        #valid_modes = (\"train\", \"train_extra\", \"val\")\n",
        "        \n",
        "        for city in os.listdir(self.images_dir):\n",
        "            img_dir = os.path.join(self.images_dir, city)\n",
        "            images_city=[]\n",
        "            for file_name in os.listdir(img_dir):\n",
        "                \n",
        "                images_city.append(os.path.join(img_dir, file_name))\n",
        "            # re.split(\\d+,input) splits by integer value\n",
        "            images_city.sort( key= lambda text: int(re.split('(\\d+)',text)[3]+re.split('(\\d+)',text) [5] ))\n",
        "            self.images+=images_city\n",
        "        \n",
        "    def paths_dir(self):\n",
        "      return(self.images)\n",
        "\n",
        "    def im_path(self):\n",
        "      return self.images            \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "             image \n",
        "        \"\"\"\n",
        "\n",
        "        image = Image.open(self.images[index]).convert('RGB')\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K9KmFu2Tnml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import json\n",
        "import os\n",
        "from collections import namedtuple\n",
        "import zipfile\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class CityscapeDataset(Dataset):\n",
        "    \"\"\"`Cityscapes <http://www.cityscapes-dataset.com/>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of dataset where directory ``leftImg8bit``\n",
        "            \n",
        "        split (string, optional): The image split to use, ``train``, ``train_extra`` or ``val``\n",
        "       \n",
        "        transform (callable, optional): A function/transform that takes in a PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``  \n",
        "        transforms (callable, optional): A function/transform that takes input sample and its target as entry\n",
        "            and returns a transformed version.\n",
        "\n",
        "    Examples:\n",
        "\n",
        "      \n",
        "    \"\"\"\n",
        "\n",
        "    # Based on https://github.com/mcordts/cityscapesScripts\n",
        "  \n",
        "\n",
        "    def __init__(self, root=None, split='train_extra', transforms=None):\n",
        "        if root is not None:\n",
        "          self.images_dir = os.path.join(self.root, 'leftImg8bit', split)\n",
        "        else:\n",
        "          self.images_dir = os.path.join('leftImg8bit', split)\n",
        "        self.split = split\n",
        "        self.images = []\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "  \n",
        "        #valid_modes = (\"train\", \"train_extra\", \"val\")\n",
        "        \n",
        "        for city in os.listdir(self.images_dir):\n",
        "            img_dir = os.path.join(self.images_dir, city)\n",
        "            images_city=[]\n",
        "            for file_name in os.listdir(img_dir):\n",
        "                \n",
        "                images_city.append(os.path.join(img_dir, file_name))\n",
        "            # re.split(\\d+,input) splits by integer value\n",
        "            images_city.sort( key= lambda text: int(re.split('(\\d+)',text)[3]+re.split('(\\d+)',text) [5] ))\n",
        "            self.images+=images_city\n",
        "        \n",
        "    def print_dir(self):\n",
        "      print(self.images)\n",
        "\n",
        "    def im_path(self):\n",
        "      return self.images            \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "             image \n",
        "        \"\"\"\n",
        "\n",
        "        image = Image.open(self.images[index]).convert('RGB')\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LdC3zJtTnmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = transforms.Resize((256, 256))\n",
        "to_tensor = transforms.ToTensor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpSu6DcVTnmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#not adding normalization as image looses textures and clrs for recostruction\n",
        "\n",
        "composed_transforms=transforms.Compose([scaler,to_tensor])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "598CAaijTnmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_dataset = CityscapeDataset(\n",
        "                                           transforms=composed_transforms\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV0CGV5kTnmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvSg9ccTTnmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x=next(iter(dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iJugmqRTnmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet50Bottom(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(ResNet50Bottom, self).__init__()\n",
        "        self.features = nn.Sequential(*list(original_model.children())[:-5])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P4hTd5fTnmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#res50_model = models.resnet50(pretrained=True)\n",
        "#res50_conv2 = ResNet50Bottom(res50_model).cuda()\n",
        "#\n",
        "#outputs = res50_conv2(x.to('cuda'))\n",
        "#outputs.data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBMR6P1dDsQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureChanger(nn.Module):\n",
        "    def __init__(self,in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.kernel_size = 1\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.conv2d_0 = torch.nn.Conv2d(in_channels, out_channels, self.kernel_size, stride=1)\n",
        "        #self.con2d_1 = torch.nn.Conv2d(out_channels*2, out_channels, kernel_size, stride=1)\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        x = self.conv2d_0(batch)\n",
        "        #x = self.con2d_1(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4cE65evRDKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskedSelfAttention(nn.Module):\n",
        "\n",
        "  def __init__(self,heads, d_model, dropout= .4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.heads = heads\n",
        "    self.soft2d = nn.Softmax2d()\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "    \n",
        "\n",
        "  def _generate_square_subsequent_mask(self, sz):\n",
        "    #sz= batch size\n",
        "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "  def mult_4d(self, batch, q_w):\n",
        "    bs= batch.shape[0]\n",
        "    layers = batch.shape[1]\n",
        "    dim1 = batch.shape[2]\n",
        "    dim2 = batch.shape[3]\n",
        "    output = torch.bmm(batch.view(bs*layers,dim1,dim2), q_w.view(bs*layers,dim1,dim2))\n",
        "    return output.view(bs,layers,dim1,dim2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, q , k, v):\n",
        "\n",
        "    #score\n",
        "    attn_output_weights = self.mult_4d(q, k.transpose(-2,-1))/math.sqrt(self.d_model/2)\n",
        "    soft_scores = self.soft2d(attn_output_weights)\n",
        "    soft_scores = self.drop(soft_scores).to('cuda')\n",
        "    output = self.mult_4d(v, soft_scores)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-iPL_1-Tnmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, bs, heads, d_model, dim1, dim2, dropout = 0.4):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.h = heads\n",
        "        self.dim1 = dim1\n",
        "        self.dim2 =dim2\n",
        "        self.dropout = dropout\n",
        "        self.nu_feat =d_model # int(d_model/self.h*2)\n",
        "        self.bs = bs\n",
        "        res50_model = models.resnet50(pretrained=True)\n",
        "        self.resnet_back = ResNet50Bottom(res50_model).cuda()\n",
        "\n",
        "\n",
        "        self.q_3d = torch.nn.Parameter(torch.empty(bs,self.nu_feat,dim1,dim2,requires_grad=True))\n",
        "        self.k_3d = torch.nn.Parameter(torch.empty(bs,self.nu_feat,dim1,dim2,requires_grad=True))\n",
        "        self.v_3d = torch.nn.Parameter(torch.empty(bs,self.nu_feat,dim1,dim2,requires_grad=True))\n",
        "   \n",
        "\n",
        "        nn.init.kaiming_normal_(self.q_3d, mode='fan_in')\n",
        "        nn.init.kaiming_normal_(self.k_3d, mode='fan_in')\n",
        "        nn.init.kaiming_normal_(self.v_3d, mode='fan_in')\n",
        "\n",
        "        self.attention_layer= MaskedSelfAttention(self.h,d_model,dropout)\n",
        "    \n",
        "    def mult_4d(self, batch, q_w, bs):\n",
        "      \n",
        "      layers = batch.shape[1]\n",
        "      dim1 = batch.shape[2]\n",
        "      dim2 = batch.shape[3]\n",
        "      #print(layers, dim1,dim2,bs)\n",
        "      #print(q_w.shape)\n",
        "      output = torch.bmm(batch.view(bs*layers,dim1,dim2), q_w.view(bs*layers,dim1,dim2))\n",
        "      return output.view(bs,layers,dim1,dim2)\n",
        "\n",
        "    def forward(self, batch, mask=None):\n",
        "        bs = batch.size(0)\n",
        "        batch = batch.to('cuda')\n",
        "        \"\"\" \n",
        "        batch = self.resnet_back(batch.to('cuda'))        \n",
        "        channels = batch.shape[1]\n",
        "        feature_layer1 = FeatureChanger(channels,int(channels/self.h*2)).cuda()\n",
        "        batch = feature_layer1(batch)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        q = self.mult_4d(batch,self.q_3d.to('cuda'),bs)\n",
        "        k = self.mult_4d(batch,self.k_3d.to('cuda'),bs)\n",
        "        v = self.mult_4d(batch,self.v_3d.to('cuda'),bs)\n",
        "\n",
        "        \"\"\"\n",
        "        #divide feature space in no of heads each head works on certain features only\n",
        "        #returns tuple of size=heads\n",
        "\n",
        "        batch_chunks= torch.chunk(batch, heads, dim=1)\n",
        "        #converting tuple to tensor\n",
        "        batch_chunks = torch.stack(batch_chunks, dim =0)\n",
        "        \"\"\"\n",
        "\n",
        "        attention_out = self.attention_layer( q, k, v)\n",
        "        #feature_layer2 = FeatureChanger(int(channels/self.h*2),channels).cuda()\n",
        "        #output = feature_layer2(batch)\n",
        "        output = attention_out\n",
        "  \n",
        "    \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wiy5LxisgFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2\n",
        "dataloader = DataLoader(transformed_dataset, batch_size,\n",
        "                        sampler=torch.utils.data.SequentialSampler(transformed_dataset) , num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFa4dkniuO4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "185859e6-e0af-4553-f01c-a8bdf0873c0c"
      },
      "source": [
        "\"\"\"\n",
        "heads = 8\n",
        "d_model = 3\n",
        "dim1 = dim2= 224\n",
        "dropout = 0.4\n",
        "\n",
        "\n",
        "MHA= MultiHeadAttention(batch_size, heads, d_model, dim1, dim2, dropout = 0.4)\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nheads = 8\\nd_model = 3\\ndim1 = dim2= 224\\ndropout = 0.4\\n\\n\\nMHA= MultiHeadAttention(batch_size, heads, d_model, dim1, dim2, dropout = 0.4)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsgWDhCXy_uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#output = MHA(next(iter(dataloader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BsfTOGr_Tk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H_WjWwsg9Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# taken from singan implementaion from repo given below\n",
        "# https://github.com/FriedRonaldo/SinGAN\n",
        "#\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_size_min, num_scale, size_list, bs, heads, d_model, dim1, dim2, dropout = 0.4, scale_factor=4/3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.img_size_min = img_size_min\n",
        "        self.scale_factor = scale_factor\n",
        "        self.num_scale = num_scale\n",
        "        self.nf = 32\n",
        "        self.current_scale = 0\n",
        "        self.d_model = d_model\n",
        "        self.h = heads\n",
        "        self.dim1 = dim1\n",
        "        self.dim2 =dim2\n",
        "        self.dropout = dropout\n",
        "        self.nu_feat =d_model # int(d_model/self.h*2)\n",
        "        self.bs = bs\n",
        "\n",
        "        self.size_list = size_list #[int(self.img_size_min * scale_factor**i) for i in range(num_scale + 1)]\n",
        "        print(self.size_list)\n",
        "        self.MHA= MultiHeadAttention(bs, heads, d_model, dim1, dim2, dropout )\n",
        "        self.sub_generators = nn.ModuleList()\n",
        "\n",
        "        first_generator = nn.ModuleList()\n",
        "\n",
        "        first_generator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1),\n",
        "                                             nn.BatchNorm2d(self.nf),\n",
        "                                             nn.LeakyReLU(2e-1)))\n",
        "        for _ in range(3):\n",
        "            first_generator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1),\n",
        "                                                 nn.BatchNorm2d(self.nf),\n",
        "                                                 nn.LeakyReLU(2e-1)))\n",
        "\n",
        "        first_generator.append(nn.Sequential(nn.Conv2d(self.nf, 3, 3, 1),\n",
        "                                             nn.Tanh()))\n",
        "\n",
        "        first_generator = nn.Sequential(*first_generator)\n",
        "\n",
        "        self.sub_generators.append(first_generator)\n",
        "\n",
        "    def forward(self, batch, img=None):\n",
        "        x_list = []\n",
        "        #print(batch[0].shape)\n",
        "        dim2 = dim1 = batch[0].shape[-1]\n",
        "        #self.MHA= MultiHeadAttention(self.bs, self.h, self.d_model,  dim1,  dim2, self.dropout )\n",
        "        #x_first = self.sub_generators[0](self.MHA(batch[0]))\n",
        "        #print(x_first.size())\n",
        "        x_first = self.sub_generators[0](batch[0])\n",
        "        x_list.append(x_first)\n",
        "\n",
        "        if img is not None:\n",
        "            x_inter = img\n",
        "        else:\n",
        "            x_inter = x_first\n",
        "\n",
        "        for i in range(1, self.current_scale + 1):\n",
        "            x_inter = F.interpolate(x_inter, (self.size_list[i], self.size_list[i]), mode='bilinear', align_corners=True)\n",
        "            #print(x_inter.size())\n",
        "            x_prev = x_inter\n",
        "            x_inter = F.pad(x_inter, [5, 5, 5, 5], value=0)\n",
        "            #print(self.current_scale)\n",
        "            dim2 = dim1 = batch[i].shape[-1]\n",
        "            \"\"\"\n",
        "            self.MHA= MultiHeadAttention(self.bs, self.h, self.d_model,  dim1,  dim2, self.dropout )\n",
        "            x_inter = x_inter + self.MHA(batch[i])\n",
        "            \"\"\"\n",
        "            x_inter = x_inter + (batch[i])\n",
        "            x_inter = self.sub_generators[i](x_inter) + x_prev\n",
        "            x_list.append(x_inter)\n",
        "        #print(self.size_list)\n",
        "        return x_list\n",
        "\n",
        "    def progress(self):\n",
        "        self.current_scale += 1\n",
        "\n",
        "        if self.current_scale % 4 == 0:\n",
        "            self.nf *= 2\n",
        "\n",
        "        tmp_generator = nn.ModuleList()\n",
        "        tmp_generator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1),\n",
        "                                           nn.BatchNorm2d(self.nf),\n",
        "                                           nn.LeakyReLU(2e-1)))\n",
        "\n",
        "        for _ in range(3):\n",
        "            tmp_generator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1),\n",
        "                                               nn.BatchNorm2d(self.nf),\n",
        "                                               nn.LeakyReLU(2e-1)))\n",
        "\n",
        "        tmp_generator.append(nn.Sequential(nn.Conv2d(self.nf, 3, 3, 1),\n",
        "                                           nn.Tanh()))\n",
        "\n",
        "        tmp_generator = nn.Sequential(*tmp_generator)\n",
        "\n",
        "        if self.current_scale % 4 != 0:\n",
        "            prev_generator = self.sub_generators[-1]\n",
        "\n",
        "            # Initialize layers via copy\n",
        "            if self.current_scale >= 1:\n",
        "                tmp_generator.load_state_dict(prev_generator.state_dict())\n",
        "\n",
        "        self.sub_generators.append(tmp_generator)\n",
        "        print(\"GENERATOR PROGRESSION DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RKtRVMPg2G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# taken from singan implementaion from repo given below\n",
        "# https://github.com/FriedRonaldo/SinGAN\n",
        "#\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.nf = 32\n",
        "        self.current_scale = 0\n",
        "\n",
        "        self.sub_discriminators = nn.ModuleList()\n",
        "\n",
        "        first_discriminator = nn.ModuleList()\n",
        "\n",
        "        first_discriminator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1, 1),\n",
        "                                             nn.LeakyReLU(2e-1)))\n",
        "        for _ in range(3):\n",
        "            first_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1, 1),\n",
        "                                                 nn.BatchNorm2d(self.nf),\n",
        "                                                 nn.LeakyReLU(2e-1)))\n",
        "\n",
        "        first_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, 1, 3, 1, 1)))\n",
        "\n",
        "        first_discriminator = nn.Sequential(*first_discriminator)\n",
        "\n",
        "        self.sub_discriminators.append(first_discriminator)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.sub_discriminators[self.current_scale](x)\n",
        "        return out\n",
        "\n",
        "    def progress(self):\n",
        "        self.current_scale += 1\n",
        "        # Lower scale discriminators are not used in later ... replace append to assign?\n",
        "        if self.current_scale % 4 == 0:\n",
        "            self.nf *= 2\n",
        "\n",
        "        tmp_discriminator = nn.ModuleList()\n",
        "        tmp_discriminator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1, 1),\n",
        "                                               nn.LeakyReLU(2e-1)))\n",
        "\n",
        "        for _ in range(3):\n",
        "            tmp_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1, 1),\n",
        "                                                   nn.BatchNorm2d(self.nf),\n",
        "                                                   nn.LeakyReLU(2e-1)))\n",
        "\n",
        "        tmp_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, 1, 3, 1, 1)))\n",
        "\n",
        "        tmp_discriminator = nn.Sequential(*tmp_discriminator)\n",
        "\n",
        "        if self.current_scale % 4 != 0:\n",
        "            prev_discriminator = self.sub_discriminators[-1]\n",
        "\n",
        "            # Initialize layers via copy\n",
        "            if self.current_scale >= 1:\n",
        "                tmp_discriminator.load_state_dict(prev_discriminator.state_dict())\n",
        "\n",
        "        self.sub_discriminators.append(tmp_discriminator)\n",
        "        print(\"DISCRIMINATOR PROGRESSION DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfjLSAcE-EMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def compute_grad_gp(d_out, x_in):\n",
        "    batch_size = x_in.size(0)\n",
        "    grad_dout = autograd.grad(\n",
        "        outputs=d_out.sum(), inputs=x_in,grad_outputs=torch.ones_like(d_out.sum()),\n",
        "        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    grad_dout2 = grad_dout.pow(2)\n",
        "    assert(grad_dout2.size() == x_in.size())\n",
        "    reg = grad_dout2.view(batch_size, -1).sum(1)\n",
        "    return reg\n",
        "\n",
        "\n",
        "def compute_grad_gp_wgan(D, x_real, x_fake, gpu):\n",
        "    alpha = torch.rand(x_real.size(0), 1, 1, 1).cuda(gpu)\n",
        "\n",
        "    x_interpolate = ((1 - alpha) * x_real + alpha * x_fake).detach()\n",
        "    x_interpolate.requires_grad = True\n",
        "    d_inter_logit = D(x_interpolate)\n",
        "    grad = torch.autograd.grad(d_inter_logit, x_interpolate,\n",
        "                               grad_outputs=torch.ones_like(d_inter_logit), create_graph=True)[0]\n",
        "\n",
        "    norm = grad.view(grad.size(0), -1).norm(p=2, dim=1)\n",
        "\n",
        "    d_gp = ((norm - 1) ** 2).mean()\n",
        "    return d_gp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiX6cKOcg1_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# taken from singan implementaion from repo given below\n",
        "# https://github.com/FriedRonaldo/SinGAN\n",
        "#\n",
        "\n",
        "from tqdm import trange\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "\n",
        "def trainSinGAN(data_loader, networks, opts, stage, args, additional):\n",
        "  # avg meter\n",
        "  d_losses = AverageMeter()\n",
        "  g_losses = AverageMeter()\n",
        "\n",
        "  # set nets\n",
        "  D = networks[0]\n",
        "  G = networks[1]\n",
        "  # set opts\n",
        "  d_opt = opts['d_opt']\n",
        "  g_opt = opts['g_opt']\n",
        "  # switch to train mode\n",
        "  D.train()\n",
        "  G.train()\n",
        "  # summary writer\n",
        "  # writer = additional[0]\n",
        "  train_it = iter(data_loader)\n",
        "  # total_iter = 2000 * (args.num_scale - stage + 1)\n",
        "  # decay_lr = 1600 * (args.num_scale - stage + 1)\n",
        "  total_iter = 2000\n",
        "  decay_lr = 4\n",
        "\n",
        "  d_iter = 3\n",
        "  g_iter = 3\n",
        "\n",
        "  t_train = trange(0, total_iter, initial=0, total=total_iter)\n",
        "  x_in = next(train_it)\n",
        "\n",
        "  x_in = x_in.cuda( non_blocking=True)\n",
        "  x_org = x_in\n",
        "  x_in = F.interpolate(x_in, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
        "  #x_0 = F.interpolate(x_0, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
        "  \n",
        "  \n",
        "\n",
        "  \"\"\"\n",
        "  z_rec = additional['z_rec']\n",
        "\n",
        "  for z_idx in range(len(z_rec)):\n",
        "      z_rec[z_idx] = z_rec[z_idx].cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "  x_in = next(train_it)\n",
        "\n",
        "  x_in = x_in.cuda(args.gpu, non_blocking=True)\n",
        "  x_org = x_in\n",
        "  x_in = F.interpolate(x_in, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
        "  vutils.save_image(x_in.detach().cpu(), os.path.join(args.res_dir, 'ORGTRAIN_{}.png'.format(stage)),\n",
        "                    nrow=1, normalize=True)\n",
        "   \"\"\"\n",
        "  x_in_list = []\n",
        "\n",
        "  for xidx in range(0, stage + 1):\n",
        "      x_tmp = F.interpolate(x_org, (args.size_list[xidx], args.size_list[xidx]), mode='bilinear', align_corners=True)\n",
        "      x_tmp = F.pad(x_tmp, [5, 5, 5, 5], value=0)\n",
        "      x_in_list.append(x_tmp)\n",
        "  \n",
        "  x_in_list_nopad = []\n",
        "  \n",
        "  for xidx in range(0, stage + 1):\n",
        "      x_tmp = F.interpolate(x_org, (args.size_list[xidx], args.size_list[xidx]), mode='bilinear', align_corners=True)\n",
        "      \n",
        "      x_in_list_nopad.append(x_tmp)\n",
        "  z_rec = F.pad(x_in, [5, 5, 5, 5], value=0)\n",
        "  for i in t_train:\n",
        "      if i == decay_lr:\n",
        "          for param_group in d_opt.param_groups:\n",
        "                  param_group['lr'] *= 0.1\n",
        "                  print(\"DISCRIMINATOR LEARNING RATE UPDATE TO :\", param_group['lr'])\n",
        "          for param_group in g_opt.param_groups:\n",
        "                  param_group['lr'] *= 0.1\n",
        "                  print(\"GENERATOR LEARNING RATE UPDATE TO :\", param_group['lr'])\n",
        "\n",
        "      for _ in range(g_iter):\n",
        "          g_opt.zero_grad()\n",
        "          #print(type(z_rec))\n",
        "          x_rec_list = G(x_in_list)\n",
        "          #print(x_rec_list[-1].shape)\n",
        "          #print(x_in.shape)\n",
        "          g_rec = F.mse_loss(x_rec_list[-1], x_in)\n",
        "          # calculate rmse for each scale\n",
        "          rmse_list = [1.0]\n",
        "          for rmseidx in range(1, stage + 1):\n",
        "              rmse = torch.sqrt(F.mse_loss(x_rec_list[rmseidx], x_in_list_nopad[rmseidx]))\n",
        "              rmse_list.append(rmse)\n",
        "\n",
        "          z_list = [F.pad(rmse_list[z_idx] * torch.randn(args.batch_size, 3, args.size_list[z_idx],\n",
        "                                              args.size_list[z_idx]).cuda(args.gpu, non_blocking=True),\n",
        "                          [5, 5, 5, 5], value=0) for z_idx in range(stage + 1)]\n",
        "          \n",
        "          x_fake_list = G(z_list )\n",
        "          #print(len(x_fake_list[-1]))\n",
        "\n",
        "          g_fake_logit = D(x_fake_list[-1])\n",
        "\n",
        "          ones = torch.ones_like(g_fake_logit).cuda(args.gpu)\n",
        "\n",
        "          if args.gantype == 'wgangp':\n",
        "              # wgan gp\n",
        "              g_fake = -torch.mean(g_fake_logit, (2, 3))\n",
        "              g_loss = g_fake + 10.0 * g_rec\n",
        "          elif args.gantype == 'zerogp':\n",
        "              # zero centered GP\n",
        "              g_fake = F.binary_cross_entropy_with_logits(g_fake_logit, ones, reduction='none').mean()\n",
        "              g_loss = g_fake + 100.0 * g_rec\n",
        "\n",
        "          elif args.gantype == 'lsgan':\n",
        "              # lsgan\n",
        "              g_fake = F.mse_loss(torch.mean(g_fake_logit, (2, 3)), 0.9 * ones)\n",
        "              g_loss = g_fake + 50.0 * g_rec\n",
        "\n",
        "          g_loss.backward(retain_graph = True)\n",
        "          g_opt.step()\n",
        "\n",
        "          g_losses.update(g_loss.item(), x_in.size(0))\n",
        "\n",
        "      # Update discriminator\n",
        "      for _ in range(d_iter):\n",
        "          x_in.requires_grad = True\n",
        "\n",
        "          d_opt.zero_grad()\n",
        "          x_fake_list =  G(z_list )\n",
        "          \n",
        "\n",
        "          d_fake_logit = g_fake_logit\n",
        "          d_real_logit = D(x_in)\n",
        "\n",
        "          ones = torch.ones_like(d_real_logit).cuda(args.gpu)\n",
        "          zeros = torch.zeros_like(d_fake_logit).cuda(args.gpu)\n",
        "\n",
        "          if args.gantype == 'wgangp':\n",
        "              # wgan gp\n",
        "              d_fake = torch.mean(d_fake_logit, (2, 3))\n",
        "              d_real = -torch.mean(d_real_logit, (2, 3))\n",
        "              d_gp = compute_grad_gp_wgan(D, x_in, x_fake_list[-1], args.gpu)\n",
        "              d_loss = d_real + d_fake + 0.1 * d_gp\n",
        "          elif args.gantype == 'zerogp':\n",
        "              # zero centered GP\n",
        "              # d_fake = F.binary_cross_entropy_with_logits(torch.mean(d_fake_logit, (2, 3)), zeros)\n",
        "              d_fake = F.binary_cross_entropy_with_logits(d_fake_logit, zeros, reduction='none').mean()\n",
        "              # d_real = F.binary_cross_entropy_with_logits(torch.mean(d_real_logit, (2, 3)), ones)\n",
        "              d_real = F.binary_cross_entropy_with_logits(d_real_logit, ones, reduction='none').mean()\n",
        "              #d_gp = compute_grad_gp(torch.mean(d_real_logit, (2, 3)), x_in)\n",
        "              d_loss = d_real + d_fake# + 10.0 * d_gp\n",
        "\n",
        "          elif args.gantype == 'lsgan':\n",
        "              # lsgan\n",
        "              d_fake = F.mse_loss(torch.mean(d_fake_logit, (2, 3)), zeros)\n",
        "              d_real = F.mse_loss(torch.mean(d_real_logit, (2, 3)), 0.9 * ones)\n",
        "              d_loss = d_real + d_fake\n",
        "\n",
        "          d_loss.backward(retain_graph=True)\n",
        "          d_opt.step()\n",
        "\n",
        "          d_losses.update(d_loss.item(), x_in.size(0))\n",
        "\n",
        "      t_train.set_description('Stage: [{}/{}] Avg Loss: D[{d_losses.avg:.3f}] G[{g_losses.avg:.3f}] RMSE[{rmse:.3f}]'\n",
        "                              .format(stage, args.num_scale, d_losses=d_losses, g_losses=g_losses, rmse=rmse_list[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIpWSvYiIxNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqRq_WkLIxLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/foo.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKgjMKYeh7yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "  def __init__(self,gpu = None,gantype = 'zerogp',model_name = 'SinGan', batch_size = 128, img_size_max= 224, img_size_min=20,\n",
        "               load_model = None, multiprocessing_distributed= None, world_size=1, log_dir= None, res_dir = None, num_scale = None):\n",
        "    self.gpu = gpu\n",
        "    self.gantype = gantype\n",
        "    self.model_name = \"SinGan\"\n",
        "    self.batch_size = batch_size\n",
        "    self.img_size_max= img_size_max\n",
        "    self.img_size_min=img_size_min\n",
        "    self.load_model = load_model\n",
        "    self.multiprocessing_distributed= multiprocessing_distributed \n",
        "    self.world_size=world_size\n",
        "    self.log_dir= log_dir\n",
        "    self.res_dir = res_dir \n",
        "    self.num_scale = num_scale \n",
        "    self.stage = None\n",
        "    self.distributed = None\n",
        "    self.workers = 8\n",
        "    self.d_model = None\n",
        "    self.h = None\n",
        "    self.dim1 = None\n",
        "    self.dim2 = None\n",
        "    self.dropout = None\n",
        "    self.nu_feat =None\n",
        "    self.dataset = None\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_RVMJm6mlbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def save_checkpoint(state, check_list, log_dir, epoch=0):\n",
        "    check_file = os.path.join(log_dir, 'model_{}.ckpt'.format(epoch))\n",
        "    torch.save(state, check_file)\n",
        "    check_list.write('model_{}.ckpt\\n'.format(epoch))\n",
        "\n",
        "def makedirs(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "def formatted_print(notice, value):\n",
        "    print('{0:<40}{1:<40}'.format(notice, value))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE0vk8BJvF0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def main_worker(gpu, ngpus_per_node, args):\n",
        "    args.gpu = 0\n",
        "\n",
        "\n",
        "    if args.gpu is not None:\n",
        "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
        "    args.distributed = False\n",
        "    if args.distributed:\n",
        "        if args.multiprocessing_distributed:\n",
        "            args.rank = args.rank * ngpus_per_node + gpu\n",
        "        dist.init_process_group(backend='nccl', init_method='tcp://127.0.0.1:'+args.port,\n",
        "                                world_size=args.world_size, rank=args.rank)\n",
        "\n",
        "    ################\n",
        "    # Define model #\n",
        "    ################\n",
        "    # 4/3 : scale factor in the paper\n",
        "    scale_factor = 4/3\n",
        "\n",
        "\n",
        "\n",
        "    tmp_scale = args.img_size_max / args.img_size_min\n",
        "    args.num_scale = int(np.round(np.log(tmp_scale) / np.log(scale_factor)))\n",
        "    args.size_list = [int(args.img_size_min * scale_factor**i) for i in range(args.num_scale + 1)]\n",
        "    #args.size_list = [int(args.img_size_min *i) for i in range(1,args.num_scale + 1)]\n",
        "\n",
        "    discriminator = Discriminator()\n",
        "    generator = Generator(args.img_size_min, args.num_scale, args.size_list, args.batch_size, args.heads, args.d_model, args.dim1, args.dim2, args.dropout,  scale_factor)\n",
        "\n",
        "    networks = [discriminator, generator]\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.gpu is not None:\n",
        "            print('Distributed to', args.gpu)\n",
        "            torch.cuda.set_device(args.gpu)\n",
        "            networks = [x.cuda(args.gpu) for x in networks]\n",
        "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
        "            args.workers = int(args.workers / ngpus_per_node)\n",
        "            networks = [torch.nn.parallel.DistributedDataParallel(x, device_ids=[args.gpu], output_device=args.gpu) for x in networks]\n",
        "        else:\n",
        "            networks = [x.cuda() for x in networks]\n",
        "            networks = [torch.nn.parallel.DistributedDataParallel(x) for x in networks]\n",
        "\n",
        "    elif args.gpu is not None:\n",
        "        torch.cuda.set_device(args.gpu)\n",
        "        networks = [x.cuda(args.gpu) for x in networks]\n",
        "    else:\n",
        "        networks = [torch.nn.DataParallel(x).cuda() for x in networks]\n",
        "\n",
        "    discriminator, generator, = networks\n",
        "\n",
        "    ######################\n",
        "    # Loss and Optimizer #\n",
        "    ######################\n",
        "    if args.distributed:\n",
        "        d_opt = torch.optim.Adam(discriminator.module.sub_discriminators[0].parameters(), 5e-4, (0.5, 0.999))\n",
        "        g_opt = torch.optim.Adam(generator.module.sub_generators[0].parameters(), 5e-4, (0.5, 0.999))\n",
        "    else:\n",
        "        d_opt = torch.optim.Adam(discriminator.sub_discriminators[0].parameters(), 5e-4, (0.5, 0.999))\n",
        "        g_opt = torch.optim.Adam(generator.sub_generators[0].parameters(), 5e-4, (0.5, 0.999))\n",
        "\n",
        "    ##############\n",
        "    # Load model #\n",
        "    ##############\n",
        "    args.stage = 0\n",
        "    if args.load_model is not None:\n",
        "        check_load = open(os.path.join(args.log_dir, \"checkpoint.txt\"), 'r')\n",
        "        to_restore = check_load.readlines()[-1].strip()\n",
        "        load_file = os.path.join(args.log_dir, to_restore)\n",
        "        if os.path.isfile(load_file):\n",
        "            print(\"=> loading checkpoint '{}'\".format(load_file))\n",
        "            checkpoint = torch.load(load_file, map_location='cpu')\n",
        "            for _ in range(int(checkpoint['stage'])):\n",
        "                generator.progress()\n",
        "                discriminator.progress()\n",
        "            networks = [discriminator, generator]\n",
        "            if args.distributed:\n",
        "                if args.gpu is not None:\n",
        "                    print('Distributed to', args.gpu)\n",
        "                    torch.cuda.set_device(args.gpu)\n",
        "                    networks = [x.cuda(args.gpu) for x in networks]\n",
        "                    args.batch_size = int(args.batch_size / ngpus_per_node)\n",
        "                    args.workers = int(args.workers / ngpus_per_node)\n",
        "                    networks = [\n",
        "                        torch.nn.parallel.DistributedDataParallel(x, device_ids=[args.gpu], output_device=args.gpu) for\n",
        "                        x in networks]\n",
        "                else:\n",
        "                    networks = [x.cuda() for x in networks]\n",
        "                    networks = [torch.nn.parallel.DistributedDataParallel(x) for x in networks]\n",
        "\n",
        "            elif args.gpu is not None:\n",
        "                torch.cuda.set_device(args.gpu)\n",
        "                networks = [x.cuda(args.gpu) for x in networks]\n",
        "            else:\n",
        "                networks = [torch.nn.DataParallel(x).cuda() for x in networks]\n",
        "\n",
        "            discriminator, generator, = networks\n",
        "\n",
        "            args.stage = checkpoint['stage']\n",
        "            args.img_to_use = checkpoint['img_to_use']\n",
        "            discriminator.load_state_dict(checkpoint['D_state_dict'])\n",
        "            generator.load_state_dict(checkpoint['G_state_dict'])\n",
        "            d_opt.load_state_dict(checkpoint['d_optimizer'])\n",
        "            g_opt.load_state_dict(checkpoint['g_optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (stage {})\"\n",
        "                  .format(load_file, checkpoint['stage']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.log_dir))\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    ###########\n",
        "    # Dataset #\n",
        "    ###########\n",
        "    transformed_dataset = CityscapeDataset(\n",
        "                                           transforms=composed_transforms\n",
        "                                           )\n",
        "\n",
        "    if args.distributed:\n",
        "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    else:\n",
        "        train_sampler = None\n",
        "\n",
        "    train_loader = DataLoader(transformed_dataset, batch_size = args.batch_size,\n",
        "                            sampler=torch.utils.data.SequentialSampler(transformed_dataset) ,  num_workers=args.workers)\n",
        "  \n",
        "\n",
        "    ######################\n",
        "    # Validate and Train #\n",
        "    ######################\n",
        "    z_fix_list = [F.pad(torch.randn(args.batch_size, 3, args.size_list[0], args.size_list[0]), [5, 5, 5, 5], value=0)]\n",
        "    zero_list = [F.pad(torch.zeros(args.batch_size, 3, args.size_list[zeros_idx], args.size_list[zeros_idx]),\n",
        "                       [5, 5, 5, 5], value=0) for zeros_idx in range(1, args.num_scale + 1)]\n",
        "    z_fix_list = z_fix_list + zero_list\n",
        "    \"\"\"\n",
        "    if args.validation:\n",
        "        validateSinGAN(train_loader, networks, args.stage, args, {\"z_rec\": z_fix_list})\n",
        "        return\n",
        "\n",
        "    elif args.test:\n",
        "        validateSinGAN(train_loader, networks, args.stage, args, {\"z_rec\": z_fix_list})\n",
        "        return\n",
        "    \"\"\"\n",
        "\n",
        "    if not args.multiprocessing_distributed or (args.multiprocessing_distributed and args.rank % ngpus_per_node == 0):\n",
        "        check_list = open(os.path.join(args.log_dir, \"checkpoint.txt\"), \"a+\")\n",
        "        record_txt = open(os.path.join(args.log_dir, \"record.txt\"), \"a+\")\n",
        "        record_txt.write('DATASET\\t:\\t{}\\n'.format(args.dataset))\n",
        "        record_txt.write('GANTYPE\\t:\\t{}\\n'.format(args.gantype))\n",
        "#        record_txt.write('IMGTOUSE\\t:\\t{}\\n'.format(args.img_to_use))\n",
        "        record_txt.close()\n",
        "\n",
        "    for stage in range(args.stage, args.num_scale + 1):\n",
        "        if args.distributed:\n",
        "            train_sampler.set_epoch(stage)\n",
        "\n",
        "        trainSinGAN(train_loader, networks, {\"d_opt\": d_opt, \"g_opt\": g_opt}, stage, args, {\"z_rec\": z_fix_list})\n",
        "       # validateSinGAN(train_loader, networks, stage, args, {\"z_rec\": z_fix_list})\n",
        "\n",
        "        if args.distributed:\n",
        "            discriminator.module.progress()\n",
        "            generator.module.progress()\n",
        "        else:\n",
        "            discriminator.progress()\n",
        "            generator.progress()\n",
        "\n",
        "        networks = [discriminator, generator]\n",
        "\n",
        "        if args.distributed:\n",
        "            if args.gpu is not None:\n",
        "                print('Distributed', args.gpu)\n",
        "                torch.cuda.set_device(args.gpu)\n",
        "                networks = [x.cuda(args.gpu) for x in networks]\n",
        "                args.batch_size = int(args.batch_size / ngpus_per_node)\n",
        "                args.workers = int(args.workers / ngpus_per_node)\n",
        "                networks = [torch.nn.parallel.DistributedDataParallel(x, device_ids=[args.gpu], output_device=args.gpu)\n",
        "                            for x in networks]\n",
        "            else:\n",
        "                networks = [x.cuda() for x in networks]\n",
        "                networks = [torch.nn.parallel.DistributedDataParallel(x) for x in networks]\n",
        "\n",
        "        elif args.gpu is not None:\n",
        "            torch.cuda.set_device(args.gpu)\n",
        "            networks = [x.cuda(args.gpu) for x in networks]\n",
        "        else:\n",
        "            networks = [torch.nn.DataParallel(x).cuda() for x in networks]\n",
        "\n",
        "        discriminator, generator, = networks\n",
        "\n",
        "        # Update the networks at finest scale\n",
        "        if args.distributed:\n",
        "            for net_idx in range(generator.module.current_scale):\n",
        "                for param in generator.module.sub_generators[net_idx].parameters():\n",
        "                    param.requires_grad = False\n",
        "                for param in discriminator.module.sub_discriminators[net_idx].parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "            d_opt = torch.optim.Adam(discriminator.module.sub_discriminators[discriminator.current_scale].parameters(),\n",
        "                                     5e-4, (0.5, 0.999))\n",
        "            g_opt = torch.optim.Adam(generator.module.sub_generators[generator.current_scale].parameters(),\n",
        "                                     5e-4, (0.5, 0.999))\n",
        "        else:\n",
        "            for net_idx in range(generator.current_scale):\n",
        "                for param in generator.sub_generators[net_idx].parameters():\n",
        "                    param.requires_grad = False\n",
        "                for param in discriminator.sub_discriminators[net_idx].parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "            d_opt = torch.optim.Adam(discriminator.sub_discriminators[discriminator.current_scale].parameters(),\n",
        "                                     5e-4, (0.5, 0.999))\n",
        "            g_opt = torch.optim.Adam(generator.sub_generators[generator.current_scale].parameters(),\n",
        "                                     5e-4, (0.5, 0.999))\n",
        "\n",
        "        ##############\n",
        "        # Save model #\n",
        "        ##############\n",
        "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed and args.rank % ngpus_per_node == 0):\n",
        "            if stage == 0:\n",
        "                check_list = open(os.path.join(args.log_dir, \"checkpoint.txt\"), \"a+\")\n",
        "            save_checkpoint({\n",
        "                'stage': stage + 1,\n",
        "                'D_state_dict': discriminator.state_dict(),\n",
        "                'G_state_dict': generator.state_dict(),\n",
        "                'd_optimizer': d_opt.state_dict(),\n",
        "                'g_optimizer': g_opt.state_dict()\n",
        "                \n",
        "            }, check_list, args.log_dir, stage + 1)\n",
        "            if stage == args.num_scale:\n",
        "                check_list.close()\n",
        "\n",
        "    return generator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVNqY1SMg17e",
        "colab_type": "code",
        "outputId": "7e561e5a-b1c8-46b0-9354-61936ddee8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "args = Arguments()\n",
        "args.gpu=0\n",
        "args.distributed = False\n",
        "args.load_model = None\n",
        "args.batch_size = 2\n",
        "args.img_size_max =  224\n",
        "args.img_size_min = 28\n",
        "args.heads = 8\n",
        "args.d_model = 3\n",
        "args.nu_feat =3\n",
        "args.dim1 = 224\n",
        "args.dim2 = 224\n",
        "args.dropout = 0.4 \n",
        "args.dataset = \"train\"\n",
        "\n",
        "if args.gpu is not None:\n",
        "   \n",
        "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
        "                  'disable data parallelism.')\n",
        "\"\"\"\n",
        "args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "ngpus_per_node = torch.cuda.device_count()\n",
        "args.load_model = None\n",
        "if args.load_model is None:\n",
        "    args.model_name = '{}_{}'.format(args.model_name, datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
        "else:\n",
        "    args.model_name = args.load_model\n",
        "\n",
        "makedirs(home/'logs')\n",
        "makedirs(home/'results')\n",
        "\n",
        "args.log_dir = os.path.join(home,'./logs', args.model_name)\n",
        "args.res_dir = os.path.join(home,'./results', args.model_name)\n",
        "\n",
        "makedirs(args.log_dir)\n",
        "makedirs(os.path.join(args.log_dir, 'codes'))\n",
        "makedirs(os.path.join(args.log_dir, 'codes', 'models'))\n",
        "makedirs(args.res_dir)\n",
        "\n",
        "if args.load_model is None:\n",
        "    pyfiles = glob(\"./*.py\")\n",
        "    modelfiles = glob('./models/*.py')\n",
        "    for py in pyfiles:\n",
        "        copyfile(py, os.path.join(args.log_dir, 'codes') + \"/\" + py)\n",
        "    for py in modelfiles:\n",
        "        copyfile(py, os.path.join(args.log_dir, 'codes', py[2:]))\n",
        "\n",
        "formatted_print('Total Number of GPUs:', ngpus_per_node)\n",
        "formatted_print('Total Number of Workers:', args.workers)\n",
        "formatted_print('Batch Size:', args.batch_size)\n",
        "formatted_print('Max image Size:', args.img_size_max)\n",
        "formatted_print('Min image Size:', args.img_size_min)\n",
        "formatted_print('Log DIR:', args.log_dir)\n",
        "formatted_print('Result DIR:', args.res_dir)\n",
        "formatted_print('GAN TYPE:', args.gantype)\n",
        "\n",
        "if args.multiprocessing_distributed:\n",
        "    args.world_size = ngpus_per_node * args.world_size\n",
        "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
        "else:\n",
        "    generator = main_worker(args.gpu, ngpus_per_node, args)\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Number of GPUs:                   1                                       \n",
            "Total Number of Workers:                8                                       \n",
            "Batch Size:                             2                                       \n",
            "Max image Size:                         224                                     \n",
            "Min image Size:                         28                                      \n",
            "Log DIR:                                drive/dl_projects/Video_Genaeration/output/./logs/SinGan_2019-11-20_23-47-25\n",
            "Result DIR:                             drive/dl_projects/Video_Genaeration/output/./results/SinGan_2019-11-20_23-47-25\n",
            "GAN TYPE:                               zerogp                                  \n",
            "Use GPU: 0 for training\n",
            "[28, 37, 49, 66, 88, 117, 157, 209]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [0/7] Avg Loss: D[1.333] G[6.504] RMSE[1.000]:  20%|██        | 4/20 [00:02<00:11,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [0/7] Avg Loss: D[1.212] G[2.629] RMSE[1.000]: 100%|██████████| 20/20 [00:03<00:00, 10.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [1/7] Avg Loss: D[1.073] G[5.347] RMSE[0.106]:  25%|██▌       | 5/20 [00:02<00:08,  1.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [1/7] Avg Loss: D[0.987] G[2.880] RMSE[0.095]: 100%|██████████| 20/20 [00:03<00:00,  5.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [2/7] Avg Loss: D[0.905] G[2.250] RMSE[0.093]:  30%|███       | 6/20 [00:02<00:08,  1.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [2/7] Avg Loss: D[0.841] G[2.096] RMSE[0.087]: 100%|██████████| 20/20 [00:03<00:00,  8.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [3/7] Avg Loss: D[0.791] G[2.131] RMSE[0.082]:  25%|██▌       | 5/20 [00:02<00:08,  1.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [3/7] Avg Loss: D[0.713] G[2.092] RMSE[0.079]: 100%|██████████| 20/20 [00:04<00:00,  4.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [4/7] Avg Loss: D[1.327] G[3.274] RMSE[0.089]:  25%|██▌       | 5/20 [00:02<00:09,  1.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [4/7] Avg Loss: D[1.202] G[2.017] RMSE[0.081]: 100%|██████████| 20/20 [00:04<00:00,  8.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [5/7] Avg Loss: D[1.102] G[1.889] RMSE[0.076]:  25%|██▌       | 5/20 [00:03<00:09,  1.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [5/7] Avg Loss: D[0.945] G[1.739] RMSE[0.073]: 100%|██████████| 20/20 [00:05<00:00,  5.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [6/7] Avg Loss: D[1.025] G[1.957] RMSE[0.082]:  20%|██        | 4/20 [00:03<00:14,  1.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [6/7] Avg Loss: D[0.818] G[1.895] RMSE[0.075]: 100%|██████████| 20/20 [00:07<00:00,  3.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [7/7] Avg Loss: D[1.138] G[1.850] RMSE[0.076]:  20%|██        | 4/20 [00:03<00:17,  1.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR LEARNING RATE UPDATE TO : 5e-05\n",
            "GENERATOR LEARNING RATE UPDATE TO : 5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Stage: [7/7] Avg Loss: D[0.880] G[1.830] RMSE[0.079]: 100%|██████████| 20/20 [00:10<00:00,  2.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DISCRIMINATOR PROGRESSION DONE\n",
            "GENERATOR PROGRESSION DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7uxyj2sg1z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = DataLoader(transformed_dataset, batch_size = args.batch_size,\n",
        "                            sampler=torch.utils.data.SequentialSampler(transformed_dataset) ,  num_workers=args.workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9C5Zl0yg1o7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(stage, generator):\n",
        "  train_it = iter(data_loader)\n",
        "\n",
        "  x_in = next(train_it)\n",
        "\n",
        "  x_in = x_in.cuda( non_blocking=True)\n",
        "  x_org = x_in\n",
        "  \n",
        "  x_in = F.interpolate(x_in, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
        "\n",
        "  x_in_list = []\n",
        "  print(len(args.size_list))\n",
        "  for xidx in range(0, stage + 1):\n",
        "      x_tmp = F.interpolate(x_org, (args.size_list[xidx], args.size_list[xidx]), mode='bilinear', align_corners=True)\n",
        "      x_tmp = F.pad(x_tmp, [5, 5, 5, 5], value=0)\n",
        "      x_in_list.append(x_tmp)\n",
        "  generator.eval()\n",
        "  out = generator(x_in_list)\n",
        "  return out\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InoOzSoSTz30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "042b7fe0-c1ba-49f9-d093-05998f7c5753"
      },
      "source": [
        "for stage in range(args.stage, args.num_scale + 1):\n",
        "  out = evaluate(stage,generator)\n",
        "  networks =  generator\n",
        "  generator.progress()\n",
        "  "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-e52deacedf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_scale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mnetworks\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-2437fe9c8847>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(stage, generator)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mx_in_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-59cf12aebc2f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mx_inter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_inter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m#print(self.current_scale)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mdim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \"\"\"\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMHA\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKnxJT2Tnmz",
        "colab_type": "code",
        "outputId": "c5c315e9-9fd1-4c4c-fe0a-9d13a61ad37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = torch.empty(500,300)\n",
        "a=  torch.empty(500,300)\n",
        "a= nn.init.kaiming_uniform_(a, mode='fan_in')\n",
        "\n",
        "\n",
        "\n",
        "nn.init.kaiming_uniform_(w, mode='fan_in')\n",
        "(a*w).argmax()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12876)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJd7tM_bTnm0",
        "colab_type": "code",
        "outputId": "062de05e-f4fc-4bca-d75c-8426e64608fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = torch.rand(32,256,20,20)\n",
        "w.argmax()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2207442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13vH6UQ-GaT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9JyekUdVRW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=torch.chunk(w,8,dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJur-8yHVVk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c=torch.reshape(w,(8,32,32,20,20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb2ul3serKvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=torch.stack(a,dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyB0dPfNtEN0",
        "colab_type": "code",
        "outputId": "f4e29fd9-5102-42bb-f0ab-83e5d8f85a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.equal(c,d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6gsdG7ouNP7",
        "colab_type": "code",
        "outputId": "5fb0720f-3472-4e58-d981-81a1224c402d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.all(torch.lt(torch.abs(torch.add(c, -d)), 1e-1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hejHXcsque3d",
        "colab_type": "code",
        "outputId": "16585917-d437-41c8-cc1b-417f4668b541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "sz=4\n",
        "mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "print(mask)\n",
        "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ True, False, False, False],\n",
            "        [ True,  True, False, False],\n",
            "        [ True,  True,  True, False],\n",
            "        [ True,  True,  True,  True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgzbZ-hMwCHZ",
        "colab_type": "code",
        "outputId": "894a11d3-766c-48f1-b3fd-b1a1210b7345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5DKNpWxwDGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = (torch.triu(torch.ones(sz, sz)) == 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXrtPkahBpC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mult_4d( batch, q_w, bs):\n",
        "  layers = batch.shape[1]\n",
        "  dim1 = batch.shape[2]\n",
        "  dim2 = batch.shape[3]\n",
        "  output = torch.bmm(batch.view(bs*layers,dim1,dim2), q_w.view(bs*layers,dim1,dim2))\n",
        "  return output.view(bs,layers,dim1,dim2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LKT4Uxxi1Ca",
        "colab_type": "code",
        "outputId": "2d3678cf-cb99-41c0-dece-d5b748e97095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "a=torch.tensor([[1,2],[3,4]])\n",
        "b=torch.tensor([[1,2],[3,4]])\n",
        "b@a\n",
        "#torch.bmm(a.unsqueeze(0),b.unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7, 10],\n",
              "        [15, 22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1X52HvABqQr",
        "colab_type": "code",
        "outputId": "d855b7bf-fc8f-4696-b0d1-90e5b972b169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = torch.rand(4,2,2,2)\n",
        "a = torch.rand(4,2,2,2)\n",
        "o=mult_4d(w,a.transpose(-2,-1),4)\n",
        "#torch.bmm(w,a).shape\n",
        "l=nn.Dropout()\n",
        "l(o).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJaUxw9xUnzs",
        "colab_type": "code",
        "outputId": "3936a479-eb33-4880-c0ca-95ca559090ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "mask= generate_square_subsequent_mask(4)\n",
        "mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATIum5xpVa22",
        "colab_type": "code",
        "outputId": "df4b70ac-cc97-427d-bdca-a113b14f595a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "mask.unsqueeze(0).unsqueeze(0)+a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-08fed53c7ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCso7oABVzfe",
        "colab_type": "code",
        "outputId": "fba15462-f265-46fc-89e9-b98668cc655c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mask.unsqueeze(0).unsqueeze(0).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Hl6lEHWcZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=nn.Softmax2d()#.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UVlYWgXTwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c= l(mult_4d(w,a,w.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYV6hRkGYmoy",
        "colab_type": "code",
        "outputId": "f56e06e6-8800-457a-bbaf-317369b7171a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixUho7w5a3zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l=nn.Softmax2d()#.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTjzmeNygWXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48eec4f8-841b-4374-f5e8-e0845e8a179b"
      },
      "source": [
        "\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 86kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.6.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.7.1 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pvu3pM1kNVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNpK5dUdj7_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_dataset = CityscapeDataset(\n",
        "                                           transforms=composed_transforms\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEoLvabej-Wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_paths = transformed_dataset.im_path()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFAo6x4GgWSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 400\n",
        "BATCH_SIZE = 32\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "OUTPUT_CHANNELS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eh4Dud3a6bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(image_file):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "\n",
        "  w = tf.shape(image)[1]\n",
        "\n",
        "  w = w // 2\n",
        "  \n",
        "  input_image = image[:, w:, :]\n",
        "\n",
        "  input_image = tf.cast(input_image, tf.float32)\n",
        "\n",
        "\n",
        "  return input_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvl0bWl6fB0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize(input_image,  height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        " \n",
        "  return input_image\n",
        "\n",
        "def random_crop(input_image):\n",
        "  stacked_image = tf.stack([input_image, input_image], axis=0)\n",
        "  cropped_image = tf.image.random_crop(\n",
        "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "  return cropped_image[0]\n",
        "\n",
        "# normalizing the images to [-1, 1]\n",
        "\n",
        "def normalize(input_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "\n",
        "\n",
        "  return input_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOweR8r7gde_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def random_jitter(input_image):\n",
        "  # resizing to 286 x 286 x 3\n",
        "  input_image = resize(input_image, 286, 286)\n",
        "\n",
        "  # randomly cropping to 256 x 256 x 3\n",
        "  input_image = random_crop(input_image)\n",
        "\n",
        "\n",
        "  return input_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxvnsQSqggFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0MT3oHgglYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_train(image_file):\n",
        "  input_image = load(image_file)\n",
        "  input_image = random_jitter(input_image)\n",
        "\n",
        "\n",
        "  return input_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcXSStloib7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This genrates batches of specified sizes, functions uded in this can fe find in other files in repo,(augmentation,preprocess)\n",
        "#It can be upadatesd for genrating  batches of test files to\n",
        "def image_generator(input_ids, batch_size = 32,is_test =False):\n",
        "  \n",
        "  while True:\n",
        "\n",
        "    if is_test:\n",
        "      batch_paths =input_ids[0:batch_size]\n",
        "      for input_id in batch_paths:\n",
        "      \n",
        "        input = load_image_train(input_id)\n",
        "            \n",
        "        batch_input += [input]\n",
        "      \n",
        "      batch_x = tf.convert_to_tensor(batch_input)\n",
        "      yield batch_input\n",
        "\n",
        "    batch_paths = np.random.choice(a= input_ids, size = batch_size)\n",
        "    \n",
        "    batch_input = []\n",
        "   \n",
        "    \n",
        "    for input_id in batch_paths:\n",
        "      #print(input_id)\n",
        "      \n",
        "      input = load_image_train(input_id)\n",
        "            \n",
        "      batch_input += [input]\n",
        "      \n",
        "    \n",
        "    batch_x = tf.convert_to_tensor(\n",
        "    batch_input,\n",
        "    dtype=None,\n",
        "    dtype_hint=None,\n",
        "    name=None\n",
        ")\n",
        "    #print(2)\n",
        "    \n",
        "    \n",
        "    yield (batch_x, batch_x)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7uivwvamqNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = image_generator(im_paths, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIiW8eJhm8jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = next(gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdoHGmVWgqX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37fdd9b4-b127-442b-bdf6-66779c23cdc7"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 256, 256, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvRRz8lhgsig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  result.add(\n",
        "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "  if apply_batchnorm:\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKkPoVsjgsej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpkA4U8Pgsah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(filters, size, apply_dropout=False):\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  result = tf.keras.Sequential()\n",
        "  \n",
        "  result.add(\n",
        "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "\n",
        "  result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  if apply_dropout:\n",
        "      result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt7NqzMBg-XP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "  down_stack = [\n",
        "    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
        "    downsample(128, 4), # (bs, 64, 64, 128)\n",
        "    downsample(256, 4), # (bs, 32, 32, 256)\n",
        "    downsample(512, 4), # (bs, 16, 16, 512)\n",
        "    downsample(512, 4), # (bs, 8, 8, 512)\n",
        "    downsample(512, 4), # (bs, 4, 4, 512)\n",
        "    downsample(512, 4), # (bs, 2, 2, 512)\n",
        "    downsample(512, 4), # (bs, 1, 1, 512)\n",
        "  ]\n",
        "\n",
        "  up_stack = [\n",
        "    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
        "    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
        "    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
        "    upsample(512, 4), # (bs, 16, 16, 1024)\n",
        "    upsample(256, 4), # (bs, 32, 32, 512)\n",
        "    upsample(128, 4), # (bs, 64, 64, 256)\n",
        "    upsample(64, 4), # (bs, 128, 128, 128)\n",
        "  ]\n",
        "\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "  \n",
        "  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                         strides=2,\n",
        "                                         padding='same',\n",
        "                                         kernel_initializer=initializer,\n",
        "                                         activation='tanh') # (bs, 256, 256, 3)\n",
        "\n",
        "  concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = []\n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qcC-ODDhBCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM-RNJyfhC_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator():\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
        "\n",
        "  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
        "\n",
        "  down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
        "  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
        "  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
        "\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
        "                                kernel_initializer=initializer,\n",
        "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
        "\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
        "\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
        "\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
        "\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
        "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm6fu0F0hGKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = Discriminator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWfefmcnhIfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LAMBDA = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIqn8OsGhNOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P1wOLzQhNLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgk4GLMghNHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTS27dImhND0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk2N5wdPhM_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = \"drive/dl_projects/Video_Genaeration/pix\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maXWgGtchWpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdawyMOChX7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input):\n",
        "  # the training=True is intentional here since\n",
        "  # we want the batch statistics while running the model\n",
        "  # on the test dataset. If we use training=False, we will get\n",
        "  # the accumulated statistics learned from the training dataset\n",
        "  # (which we don't want)\n",
        "  prediction = model(test_input, training=True)\n",
        "  plt.figure(figsize=(15,15))\n",
        "\n",
        "  display_list = [test_input[0], prediction[0]]\n",
        "  title = ['ground Image',  'Predicted Image']\n",
        "\n",
        "  for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2RDQlrDhX21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_step(input_image, target):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image, training=True)\n",
        "\n",
        "    disc_real_output = discriminator([input_image, target], training=True)\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "\n",
        "    gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDzge0c_uffA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjkG4WQchXyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  print(1)\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    input_image , target = next(dataset)\n",
        "    train_step(input_image, target)\n",
        "\n",
        "    \n",
        "\n",
        "    # saving (checkpoint) the model every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhfD2V7mtfRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gen = image_generator(im_paths, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN3I3QtTvOOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "938d197f-ffd8-4233-8573-dc654b61830e"
      },
      "source": [
        "x,y=(next(gen))\n",
        "x.shape"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 256, 256, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1obMOTociHnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "57e534c0-76b6-44d9-ebc8-bd2cdd1625b8"
      },
      "source": [
        "EPOCHS = 200\n",
        "train((gen), EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Time taken for epoch 1 is 12.370551347732544 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4azY1JKzhXvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwvlqWm3hXrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM3hBIWEhXox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxuygKJlhXjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWf9FE_zhXco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}