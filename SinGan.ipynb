{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-989d191c7cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://github.com/FriedRonaldo/SinGAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# taken from singan implementaion from repo given below\n",
    "# https://github.com/FriedRonaldo/SinGAN\n",
    "#\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size_min, num_scale, size_list, bs, heads, d_model, dim1, dim2, dropout = 0.4, scale_factor=4/3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_size_min = img_size_min\n",
    "        self.scale_factor = scale_factor\n",
    "        self.num_scale = num_scale\n",
    "        self.nf = 32\n",
    "        self.current_scale = 0\n",
    "        self.d_model = d_model\n",
    "        self.h = heads\n",
    "        self.dim1 = dim1\n",
    "        self.dim2 =dim2\n",
    "        self.dropout = dropout\n",
    "        self.nu_feat =d_model # int(d_model/self.h*2)\n",
    "        self.bs = bs\n",
    "\n",
    "        self.size_list = size_list #[int(self.img_size_min * scale_factor**i) for i in range(num_scale + 1)]\n",
    "        print(self.size_list)\n",
    "        self.MHA= MultiHeadAttention(bs, heads, d_model, dim1, dim2, dropout )\n",
    "        self.sub_generators = nn.ModuleList()\n",
    "\n",
    "        first_generator = nn.ModuleList()\n",
    "\n",
    "        first_generator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1),\n",
    "                                             nn.BatchNorm2d(self.nf),\n",
    "                                             nn.LeakyReLU(2e-1)))\n",
    "        for _ in range(3):\n",
    "            first_generator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1),\n",
    "                                                 nn.BatchNorm2d(self.nf),\n",
    "                                                 nn.LeakyReLU(2e-1)))\n",
    "\n",
    "        first_generator.append(nn.Sequential(nn.Conv2d(self.nf, 3, 3, 1),\n",
    "                                             nn.Tanh()))\n",
    "\n",
    "        first_generator = nn.Sequential(*first_generator)\n",
    "\n",
    "        self.sub_generators.append(first_generator)\n",
    "\n",
    "    def forward(self, batch, img=None):\n",
    "        x_list = []\n",
    "        #print(batch[0].shape)\n",
    "        dim2 = dim1 = batch[0].shape[-1]\n",
    "        #self.MHA= MultiHeadAttention(self.bs, self.h, self.d_model,  dim1,  dim2, self.dropout )\n",
    "        #x_first = self.sub_generators[0](self.MHA(batch[0]))\n",
    "        #print(x_first.size())\n",
    "        x_first = self.sub_generators[0](batch[0])\n",
    "        x_list.append(x_first)\n",
    "\n",
    "        if img is not None:\n",
    "            x_inter = img\n",
    "        else:\n",
    "            x_inter = x_first\n",
    "\n",
    "        for i in range(1, self.current_scale + 1):\n",
    "            x_inter = F.interpolate(x_inter, (self.size_list[i], self.size_list[i]), mode='bilinear', align_corners=True)\n",
    "            #print(x_inter.size())\n",
    "            x_prev = x_inter\n",
    "            x_inter = F.pad(x_inter, [5, 5, 5, 5], value=0)\n",
    "            #print(self.current_scale)\n",
    "            dim2 = dim1 = batch[i].shape[-1]\n",
    "            \"\"\"\n",
    "            self.MHA= MultiHeadAttention(self.bs, self.h, self.d_model,  dim1,  dim2, self.dropout )\n",
    "            x_inter = x_inter + self.MHA(batch[i])\n",
    "            \"\"\"\n",
    "            x_inter = x_inter + (batch[i])\n",
    "            x_inter = self.sub_generators[i](x_inter) + x_prev\n",
    "            x_list.append(x_inter)\n",
    "        #print(self.size_list)\n",
    "        return x_list\n",
    "\n",
    "    def progress(self):\n",
    "        self.current_scale += 1\n",
    "\n",
    "        if self.current_scale % 4 == 0:\n",
    "            self.nf *= 2\n",
    "\n",
    "        tmp_generator = nn.ModuleList()\n",
    "        tmp_generator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1),\n",
    "                                           nn.BatchNorm2d(self.nf),\n",
    "                                           nn.LeakyReLU(2e-1)))\n",
    "\n",
    "        for _ in range(3):\n",
    "            tmp_generator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1),\n",
    "                                               nn.BatchNorm2d(self.nf),\n",
    "                                               nn.LeakyReLU(2e-1)))\n",
    "\n",
    "        tmp_generator.append(nn.Sequential(nn.Conv2d(self.nf, 3, 3, 1),\n",
    "                                           nn.Tanh()))\n",
    "\n",
    "        tmp_generator = nn.Sequential(*tmp_generator)\n",
    "\n",
    "        if self.current_scale % 4 != 0:\n",
    "            prev_generator = self.sub_generators[-1]\n",
    "\n",
    "            # Initialize layers via copy\n",
    "            if self.current_scale >= 1:\n",
    "                tmp_generator.load_state_dict(prev_generator.state_dict())\n",
    "\n",
    "        self.sub_generators.append(tmp_generator)\n",
    "        print(\"GENERATOR PROGRESSION DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from singan implementaion from repo given below\n",
    "# https://github.com/FriedRonaldo/SinGAN\n",
    "#\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.nf = 32\n",
    "        self.current_scale = 0\n",
    "\n",
    "        self.sub_discriminators = nn.ModuleList()\n",
    "\n",
    "        first_discriminator = nn.ModuleList()\n",
    "\n",
    "        first_discriminator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1, 1),\n",
    "                                             nn.LeakyReLU(2e-1)))\n",
    "        for _ in range(3):\n",
    "            first_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1, 1),\n",
    "                                                 nn.BatchNorm2d(self.nf),\n",
    "                                                 nn.LeakyReLU(2e-1)))\n",
    "\n",
    "        first_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, 1, 3, 1, 1)))\n",
    "\n",
    "        first_discriminator = nn.Sequential(*first_discriminator)\n",
    "\n",
    "        self.sub_discriminators.append(first_discriminator)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.sub_discriminators[self.current_scale](x)\n",
    "        return out\n",
    "\n",
    "    def progress(self):\n",
    "        self.current_scale += 1\n",
    "        # Lower scale discriminators are not used in later ... replace append to assign?\n",
    "        if self.current_scale % 4 == 0:\n",
    "            self.nf *= 2\n",
    "\n",
    "        tmp_discriminator = nn.ModuleList()\n",
    "        tmp_discriminator.append(nn.Sequential(nn.Conv2d(3, self.nf, 3, 1, 1),\n",
    "                                               nn.LeakyReLU(2e-1)))\n",
    "\n",
    "        for _ in range(3):\n",
    "            tmp_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, self.nf, 3, 1, 1),\n",
    "                                                   nn.BatchNorm2d(self.nf),\n",
    "                                                   nn.LeakyReLU(2e-1)))\n",
    "\n",
    "        tmp_discriminator.append(nn.Sequential(nn.Conv2d(self.nf, 1, 3, 1, 1)))\n",
    "\n",
    "        tmp_discriminator = nn.Sequential(*tmp_discriminator)\n",
    "\n",
    "        if self.current_scale % 4 != 0:\n",
    "            prev_discriminator = self.sub_discriminators[-1]\n",
    "\n",
    "            # Initialize layers via copy\n",
    "            if self.current_scale >= 1:\n",
    "                tmp_discriminator.load_state_dict(prev_discriminator.state_dict())\n",
    "\n",
    "        self.sub_discriminators.append(tmp_discriminator)\n",
    "        print(\"DISCRIMINATOR PROGRESSION DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def compute_grad_gp(d_out, x_in):\n",
    "    batch_size = x_in.size(0)\n",
    "    grad_dout = autograd.grad(\n",
    "        outputs=d_out.sum(), inputs=x_in,grad_outputs=torch.ones_like(d_out.sum()),\n",
    "        create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    grad_dout2 = grad_dout.pow(2)\n",
    "    assert(grad_dout2.size() == x_in.size())\n",
    "    reg = grad_dout2.view(batch_size, -1).sum(1)\n",
    "    return reg\n",
    "\n",
    "\n",
    "def compute_grad_gp_wgan(D, x_real, x_fake, gpu):\n",
    "    alpha = torch.rand(x_real.size(0), 1, 1, 1).cuda(gpu)\n",
    "\n",
    "    x_interpolate = ((1 - alpha) * x_real + alpha * x_fake).detach()\n",
    "    x_interpolate.requires_grad = True\n",
    "    d_inter_logit = D(x_interpolate)\n",
    "    grad = torch.autograd.grad(d_inter_logit, x_interpolate,\n",
    "                               grad_outputs=torch.ones_like(d_inter_logit), create_graph=True)[0]\n",
    "\n",
    "    norm = grad.view(grad.size(0), -1).norm(p=2, dim=1)\n",
    "\n",
    "    d_gp = ((norm - 1) ** 2).mean()\n",
    "    return d_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from singan implementaion from repo given below\n",
    "# https://github.com/FriedRonaldo/SinGAN\n",
    "#\n",
    "\n",
    "from tqdm import trange\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "def trainSinGAN(data_loader, networks, opts, stage, args, additional):\n",
    "  # avg meter\n",
    "  d_losses = AverageMeter()\n",
    "  g_losses = AverageMeter()\n",
    "\n",
    "  # set nets\n",
    "  D = networks[0]\n",
    "  G = networks[1]\n",
    "  # set opts\n",
    "  d_opt = opts['d_opt']\n",
    "  g_opt = opts['g_opt']\n",
    "  # switch to train mode\n",
    "  D.train()\n",
    "  G.train()\n",
    "  # summary writer\n",
    "  # writer = additional[0]\n",
    "  train_it = iter(data_loader)\n",
    "  # total_iter = 2000 * (args.num_scale - stage + 1)\n",
    "  # decay_lr = 1600 * (args.num_scale - stage + 1)\n",
    "  total_iter = 2000\n",
    "  decay_lr = 4\n",
    "\n",
    "  d_iter = 3\n",
    "  g_iter = 3\n",
    "\n",
    "  t_train = trange(0, total_iter, initial=0, total=total_iter)\n",
    "  x_in = next(train_it)\n",
    "\n",
    "  x_in = x_in.cuda( non_blocking=True)\n",
    "  x_org = x_in\n",
    "  x_in = F.interpolate(x_in, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
    "  #x_0 = F.interpolate(x_0, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
    "  \n",
    "  \n",
    "\n",
    "  \"\"\"\n",
    "  z_rec = additional['z_rec']\n",
    "\n",
    "  for z_idx in range(len(z_rec)):\n",
    "      z_rec[z_idx] = z_rec[z_idx].cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "  x_in = next(train_it)\n",
    "\n",
    "  x_in = x_in.cuda(args.gpu, non_blocking=True)\n",
    "  x_org = x_in\n",
    "  x_in = F.interpolate(x_in, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
    "  vutils.save_image(x_in.detach().cpu(), os.path.join(args.res_dir, 'ORGTRAIN_{}.png'.format(stage)),\n",
    "                    nrow=1, normalize=True)\n",
    "   \"\"\"\n",
    "  x_in_list = []\n",
    "\n",
    "  for xidx in range(0, stage + 1):\n",
    "      x_tmp = F.interpolate(x_org, (args.size_list[xidx], args.size_list[xidx]), mode='bilinear', align_corners=True)\n",
    "      x_tmp = F.pad(x_tmp, [5, 5, 5, 5], value=0)\n",
    "      x_in_list.append(x_tmp)\n",
    "  \n",
    "  x_in_list_nopad = []\n",
    "  \n",
    "  for xidx in range(0, stage + 1):\n",
    "      x_tmp = F.interpolate(x_org, (args.size_list[xidx], args.size_list[xidx]), mode='bilinear', align_corners=True)\n",
    "      \n",
    "      x_in_list_nopad.append(x_tmp)\n",
    "  z_rec = F.pad(x_in, [5, 5, 5, 5], value=0)\n",
    "  for i in t_train:\n",
    "      if i == decay_lr:\n",
    "          for param_group in d_opt.param_groups:\n",
    "                  param_group['lr'] *= 0.1\n",
    "                  print(\"DISCRIMINATOR LEARNING RATE UPDATE TO :\", param_group['lr'])\n",
    "          for param_group in g_opt.param_groups:\n",
    "                  param_group['lr'] *= 0.1\n",
    "                  print(\"GENERATOR LEARNING RATE UPDATE TO :\", param_group['lr'])\n",
    "\n",
    "      for _ in range(g_iter):\n",
    "          g_opt.zero_grad()\n",
    "          #print(type(z_rec))\n",
    "          x_rec_list = G(x_in_list)\n",
    "          #print(x_rec_list[-1].shape)\n",
    "          #print(x_in.shape)\n",
    "          g_rec = F.mse_loss(x_rec_list[-1], x_in)\n",
    "          # calculate rmse for each scale\n",
    "          rmse_list = [1.0]\n",
    "          for rmseidx in range(1, stage + 1):\n",
    "              rmse = torch.sqrt(F.mse_loss(x_rec_list[rmseidx], x_in_list_nopad[rmseidx]))\n",
    "              rmse_list.append(rmse)\n",
    "\n",
    "          z_list = [F.pad(rmse_list[z_idx] * torch.randn(args.batch_size, 3, args.size_list[z_idx],\n",
    "                                              args.size_list[z_idx]).cuda(args.gpu, non_blocking=True),\n",
    "                          [5, 5, 5, 5], value=0) for z_idx in range(stage + 1)]\n",
    "          \n",
    "          x_fake_list = G(z_list )\n",
    "          #print(len(x_fake_list[-1]))\n",
    "\n",
    "          g_fake_logit = D(x_fake_list[-1])\n",
    "\n",
    "          ones = torch.ones_like(g_fake_logit).cuda(args.gpu)\n",
    "\n",
    "          if args.gantype == 'wgangp':\n",
    "              # wgan gp\n",
    "              g_fake = -torch.mean(g_fake_logit, (2, 3))\n",
    "              g_loss = g_fake + 10.0 * g_rec\n",
    "          elif args.gantype == 'zerogp':\n",
    "              # zero centered GP\n",
    "              g_fake = F.binary_cross_entropy_with_logits(g_fake_logit, ones, reduction='none').mean()\n",
    "              g_loss = g_fake + 100.0 * g_rec\n",
    "\n",
    "          elif args.gantype == 'lsgan':\n",
    "              # lsgan\n",
    "              g_fake = F.mse_loss(torch.mean(g_fake_logit, (2, 3)), 0.9 * ones)\n",
    "              g_loss = g_fake + 50.0 * g_rec\n",
    "\n",
    "          g_loss.backward(retain_graph = True)\n",
    "          g_opt.step()\n",
    "\n",
    "          g_losses.update(g_loss.item(), x_in.size(0))\n",
    "\n",
    "      # Update discriminator\n",
    "      for _ in range(d_iter):\n",
    "          x_in.requires_grad = True\n",
    "\n",
    "          d_opt.zero_grad()\n",
    "          x_fake_list =  G(z_list )\n",
    "          \n",
    "\n",
    "          d_fake_logit = g_fake_logit\n",
    "          d_real_logit = D(x_in)\n",
    "\n",
    "          ones = torch.ones_like(d_real_logit).cuda(args.gpu)\n",
    "          zeros = torch.zeros_like(d_fake_logit).cuda(args.gpu)\n",
    "\n",
    "          if args.gantype == 'wgangp':\n",
    "              # wgan gp\n",
    "              d_fake = torch.mean(d_fake_logit, (2, 3))\n",
    "              d_real = -torch.mean(d_real_logit, (2, 3))\n",
    "              d_gp = compute_grad_gp_wgan(D, x_in, x_fake_list[-1], args.gpu)\n",
    "              d_loss = d_real + d_fake + 0.1 * d_gp\n",
    "          elif args.gantype == 'zerogp':\n",
    "              # zero centered GP\n",
    "              # d_fake = F.binary_cross_entropy_with_logits(torch.mean(d_fake_logit, (2, 3)), zeros)\n",
    "              d_fake = F.binary_cross_entropy_with_logits(d_fake_logit, zeros, reduction='none').mean()\n",
    "              # d_real = F.binary_cross_entropy_with_logits(torch.mean(d_real_logit, (2, 3)), ones)\n",
    "              d_real = F.binary_cross_entropy_with_logits(d_real_logit, ones, reduction='none').mean()\n",
    "              #d_gp = compute_grad_gp(torch.mean(d_real_logit, (2, 3)), x_in)\n",
    "              d_loss = d_real + d_fake# + 10.0 * d_gp\n",
    "\n",
    "          elif args.gantype == 'lsgan':\n",
    "              # lsgan\n",
    "              d_fake = F.mse_loss(torch.mean(d_fake_logit, (2, 3)), zeros)\n",
    "              d_real = F.mse_loss(torch.mean(d_real_logit, (2, 3)), 0.9 * ones)\n",
    "              d_loss = d_real + d_fake\n",
    "\n",
    "          d_loss.backward(retain_graph=True)\n",
    "          d_opt.step()\n",
    "\n",
    "          d_losses.update(d_loss.item(), x_in.size(0))\n",
    "\n",
    "      t_train.set_description('Stage: [{}/{}] Avg Loss: D[{d_losses.avg:.3f}] G[{g_losses.avg:.3f}] RMSE[{rmse:.3f}]'\n",
    "                              .format(stage, args.num_scale, d_losses=d_losses, g_losses=g_losses, rmse=rmse_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
    "  f.write('Hello Google Drive!')\n",
    "!cat '/gdrive/My Drive/foo.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "  def __init__(self,gpu = None,gantype = 'zerogp',model_name = 'SinGan', batch_size = 128, img_size_max= 224, img_size_min=20,\n",
    "               load_model = None, multiprocessing_distributed= None, world_size=1, log_dir= None, res_dir = None, num_scale = None):\n",
    "    self.gpu = gpu\n",
    "    self.gantype = gantype\n",
    "    self.model_name = \"SinGan\"\n",
    "    self.batch_size = batch_size\n",
    "    self.img_size_max= img_size_max\n",
    "    self.img_size_min=img_size_min\n",
    "    self.load_model = load_model\n",
    "    self.multiprocessing_distributed= multiprocessing_distributed \n",
    "    self.world_size=world_size\n",
    "    self.log_dir= log_dir\n",
    "    self.res_dir = res_dir \n",
    "    self.num_scale = num_scale \n",
    "    self.stage = None\n",
    "    self.distributed = None\n",
    "    self.workers = 8\n",
    "    self.d_model = None\n",
    "    self.h = None\n",
    "    self.dim1 = None\n",
    "    self.dim2 = None\n",
    "    self.dropout = None\n",
    "    self.nu_feat =None\n",
    "    self.dataset = None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(state, check_list, log_dir, epoch=0):\n",
    "    check_file = os.path.join(log_dir, 'model_{}.ckpt'.format(epoch))\n",
    "    torch.save(state, check_file)\n",
    "    check_list.write('model_{}.ckpt\\n'.format(epoch))\n",
    "\n",
    "def makedirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "def formatted_print(notice, value):\n",
    "    print('{0:<40}{1:<40}'.format(notice, value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    args.gpu = 0\n",
    "\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "    args.distributed = False\n",
    "    if args.distributed:\n",
    "        if args.multiprocessing_distributed:\n",
    "            args.rank = args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend='nccl', init_method='tcp://127.0.0.1:'+args.port,\n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "\n",
    "    ################\n",
    "    # Define model #\n",
    "    ################\n",
    "    # 4/3 : scale factor in the paper\n",
    "    scale_factor = 4/3\n",
    "\n",
    "\n",
    "\n",
    "    tmp_scale = args.img_size_max / args.img_size_min\n",
    "    args.num_scale = int(np.round(np.log(tmp_scale) / np.log(scale_factor)))\n",
    "    args.size_list = [int(args.img_size_min * scale_factor**i) for i in range(args.num_scale + 1)]\n",
    "    #args.size_list = [int(args.img_size_min *i) for i in range(1,args.num_scale + 1)]\n",
    "\n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator(args.img_size_min, args.num_scale, args.size_list, args.batch_size, args.heads, args.d_model, args.dim1, args.dim2, args.dropout,  scale_factor)\n",
    "\n",
    "    networks = [discriminator, generator]\n",
    "\n",
    "    if args.distributed:\n",
    "        if args.gpu is not None:\n",
    "            print('Distributed to', args.gpu)\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            networks = [x.cuda(args.gpu) for x in networks]\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "            args.workers = int(args.workers / ngpus_per_node)\n",
    "            networks = [torch.nn.parallel.DistributedDataParallel(x, device_ids=[args.gpu], output_device=args.gpu) for x in networks]\n",
    "        else:\n",
    "            networks = [x.cuda() for x in networks]\n",
    "            networks = [torch.nn.parallel.DistributedDataParallel(x) for x in networks]\n",
    "\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        networks = [x.cuda(args.gpu) for x in networks]\n",
    "    else:\n",
    "        networks = [torch.nn.DataParallel(x).cuda() for x in networks]\n",
    "\n",
    "    discriminator, generator, = networks\n",
    "\n",
    "    ######################\n",
    "    # Loss and Optimizer #\n",
    "    ######################\n",
    "    if args.distributed:\n",
    "        d_opt = torch.optim.Adam(discriminator.module.sub_discriminators[0].parameters(), 5e-4, (0.5, 0.999))\n",
    "        g_opt = torch.optim.Adam(generator.module.sub_generators[0].parameters(), 5e-4, (0.5, 0.999))\n",
    "    else:\n",
    "        d_opt = torch.optim.Adam(discriminator.sub_discriminators[0].parameters(), 5e-4, (0.5, 0.999))\n",
    "        g_opt = torch.optim.Adam(generator.sub_generators[0].parameters(), 5e-4, (0.5, 0.999))\n",
    "\n",
    "    ##############\n",
    "    # Load model #\n",
    "    ##############\n",
    "    args.stage = 0\n",
    "    if args.load_model is not None:\n",
    "        check_load = open(os.path.join(args.log_dir, \"checkpoint.txt\"), 'r')\n",
    "        to_restore = check_load.readlines()[-1].strip()\n",
    "        load_file = os.path.join(args.log_dir, to_restore)\n",
    "        if os.path.isfile(load_file):\n",
    "            print(\"=> loading checkpoint '{}'\".format(load_file))\n",
    "            checkpoint = torch.load(load_file, map_location='cpu')\n",
    "            for _ in range(int(checkpoint['stage'])):\n",
    "                generator.progress()\n",
    "                discriminator.progress()\n",
    "            networks = [discriminator, generator]\n",
    "            if args.distributed:\n",
    "                if args.gpu is not None:\n",
    "                    print('Distributed to', args.gpu)\n",
    "                    torch.cuda.set_device(args.gpu)\n",
    "                    networks = [x.cuda(args.gpu) for x in networks]\n",
    "                    args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "                    args.workers = int(args.workers / ngpus_per_node)\n",
    "                    networks = [\n",
    "                        torch.nn.parallel.DistributedDataParallel(x, device_ids=[args.gpu], output_device=args.gpu) for\n",
    "                        x in networks]\n",
    "                else:\n",
    "                    networks = [x.cuda() for x in networks]\n",
    "                    networks = [torch.nn.parallel.DistributedDataParallel(x) for x in networks]\n",
    "\n",
    "            elif args.gpu is not None:\n",
    "                torch.cuda.set_device(args.gpu)\n",
    "                networks = [x.cuda(args.gpu) for x in networks]\n",
    "            else:\n",
    "                networks = [torch.nn.DataParallel(x).cuda() for x in networks]\n",
    "\n",
    "            discriminator, generator, = networks\n",
    "\n",
    "            args.stage = checkpoint['stage']\n",
    "            args.img_to_use = checkpoint['img_to_use']\n",
    "            discriminator.load_state_dict(checkpoint['D_state_dict'])\n",
    "            generator.load_state_dict(checkpoint['G_state_dict'])\n",
    "            d_opt.load_state_dict(checkpoint['d_optimizer'])\n",
    "            g_opt.load_state_dict(checkpoint['g_optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (stage {})\"\n",
    "                  .format(load_file, checkpoint['stage']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.log_dir))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    ###########\n",
    "    # Dataset #\n",
    "    ###########\n",
    "    transformed_dataset = CityscapeDataset(\n",
    "                                           transforms=composed_transforms\n",
    "                                           )\n",
    "\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "\n",
    "    train_loader = DataLoader(transformed_dataset, batch_size = args.batch_size,\n",
    "                            sampler=torch.utils.data.SequentialSampler(transformed_dataset) ,  num_workers=args.workers)\n",
    "  \n",
    "\n",
    "    ######################\n",
    "    # Validate and Train #\n",
    "    ######################\n",
    "    z_fix_list = [F.pad(torch.randn(args.batch_size, 3, args.size_list[0], args.size_list[0]), [5, 5, 5, 5], value=0)]\n",
    "    zero_list = [F.pad(torch.zeros(args.batch_size, 3, args.size_list[zeros_idx], args.size_list[zeros_idx]),\n",
    "                       [5, 5, 5, 5], value=0) for zeros_idx in range(1, args.num_scale + 1)]\n",
    "    z_fix_list = z_fix_list + zero_list\n",
    "    \"\"\"\n",
    "    if args.validation:\n",
    "        validateSinGAN(train_loader, networks, args.stage, args, {\"z_rec\": z_fix_list})\n",
    "        return\n",
    "\n",
    "    elif args.test:\n",
    "        validateSinGAN(train_loader, networks, args.stage, args, {\"z_rec\": z_fix_list})\n",
    "        return\n",
    "    \"\"\"\n",
    "\n",
    "    if not args.multiprocessing_distributed or (args.multiprocessing_distributed and args.rank % ngpus_per_node == 0):\n",
    "        check_list = open(os.path.join(args.log_dir, \"checkpoint.txt\"), \"a+\")\n",
    "        record_txt = open(os.path.join(args.log_dir, \"record.txt\"), \"a+\")\n",
    "        record_txt.write('DATASET\\t:\\t{}\\n'.format(args.dataset))\n",
    "        record_txt.write('GANTYPE\\t:\\t{}\\n'.format(args.gantype))\n",
    "#        record_txt.write('IMGTOUSE\\t:\\t{}\\n'.format(args.img_to_use))\n",
    "        record_txt.close()\n",
    "\n",
    "    for stage in range(args.stage, args.num_scale + 1):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(stage)\n",
    "\n",
    "        trainSinGAN(train_loader, networks, {\"d_opt\": d_opt, \"g_opt\": g_opt}, stage, args, {\"z_rec\": z_fix_list})\n",
    "       # validateSinGAN(train_loader, networks, stage, args, {\"z_rec\": z_fix_list})\n",
    "\n",
    "        if args.distributed:\n",
    "            discriminator.module.progress()\n",
    "            generator.module.progress()\n",
    "        else:\n",
    "            discriminator.progress()\n",
    "            generator.progress()\n",
    "\n",
    "        networks = [discriminator, generator]\n",
    "\n",
    "        if args.distributed:\n",
    "            if args.gpu is not None:\n",
    "                print('Distributed', args.gpu)\n",
    "                torch.cuda.set_device(args.gpu)\n",
    "                networks = [x.cuda(args.gpu) for x in networks]\n",
    "                args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "                args.workers = int(args.workers / ngpus_per_node)\n",
    "                networks = [torch.nn.parallel.DistributedDataParallel(x, device_ids=[args.gpu], output_device=args.gpu)\n",
    "                            for x in networks]\n",
    "            else:\n",
    "                networks = [x.cuda() for x in networks]\n",
    "                networks = [torch.nn.parallel.DistributedDataParallel(x) for x in networks]\n",
    "\n",
    "        elif args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            networks = [x.cuda(args.gpu) for x in networks]\n",
    "        else:\n",
    "            networks = [torch.nn.DataParallel(x).cuda() for x in networks]\n",
    "\n",
    "        discriminator, generator, = networks\n",
    "\n",
    "        # Update the networks at finest scale\n",
    "        if args.distributed:\n",
    "            for net_idx in range(generator.module.current_scale):\n",
    "                for param in generator.module.sub_generators[net_idx].parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in discriminator.module.sub_discriminators[net_idx].parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            d_opt = torch.optim.Adam(discriminator.module.sub_discriminators[discriminator.current_scale].parameters(),\n",
    "                                     5e-4, (0.5, 0.999))\n",
    "            g_opt = torch.optim.Adam(generator.module.sub_generators[generator.current_scale].parameters(),\n",
    "                                     5e-4, (0.5, 0.999))\n",
    "        else:\n",
    "            for net_idx in range(generator.current_scale):\n",
    "                for param in generator.sub_generators[net_idx].parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in discriminator.sub_discriminators[net_idx].parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            d_opt = torch.optim.Adam(discriminator.sub_discriminators[discriminator.current_scale].parameters(),\n",
    "                                     5e-4, (0.5, 0.999))\n",
    "            g_opt = torch.optim.Adam(generator.sub_generators[generator.current_scale].parameters(),\n",
    "                                     5e-4, (0.5, 0.999))\n",
    "\n",
    "        ##############\n",
    "        # Save model #\n",
    "        ##############\n",
    "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed and args.rank % ngpus_per_node == 0):\n",
    "            if stage == 0:\n",
    "                check_list = open(os.path.join(args.log_dir, \"checkpoint.txt\"), \"a+\")\n",
    "            save_checkpoint({\n",
    "                'stage': stage + 1,\n",
    "                'D_state_dict': discriminator.state_dict(),\n",
    "                'G_state_dict': generator.state_dict(),\n",
    "                'd_optimizer': d_opt.state_dict(),\n",
    "                'g_optimizer': g_opt.state_dict()\n",
    "                \n",
    "            }, check_list, args.log_dir, stage + 1)\n",
    "            if stage == args.num_scale:\n",
    "                check_list.close()\n",
    "\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.gpu=0\n",
    "args.distributed = False\n",
    "args.load_model = None\n",
    "args.batch_size = 2\n",
    "args.img_size_max =  224\n",
    "args.img_size_min = 28\n",
    "args.heads = 8\n",
    "args.d_model = 3\n",
    "args.nu_feat =3\n",
    "args.dim1 = 224\n",
    "args.dim2 = 224\n",
    "args.dropout = 0.4 \n",
    "args.dataset = \"train\"\n",
    "\n",
    "if args.gpu is not None:\n",
    "   \n",
    "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                  'disable data parallelism.')\n",
    "\"\"\"\n",
    "args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ngpus_per_node = torch.cuda.device_count()\n",
    "args.load_model = None\n",
    "if args.load_model is None:\n",
    "    args.model_name = '{}_{}'.format(args.model_name, datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "else:\n",
    "    args.model_name = args.load_model\n",
    "\n",
    "makedirs(home/'logs')\n",
    "makedirs(home/'results')\n",
    "\n",
    "args.log_dir = os.path.join(home,'./logs', args.model_name)\n",
    "args.res_dir = os.path.join(home,'./results', args.model_name)\n",
    "\n",
    "makedirs(args.log_dir)\n",
    "makedirs(os.path.join(args.log_dir, 'codes'))\n",
    "makedirs(os.path.join(args.log_dir, 'codes', 'models'))\n",
    "makedirs(args.res_dir)\n",
    "\n",
    "if args.load_model is None:\n",
    "    pyfiles = glob(\"./*.py\")\n",
    "    modelfiles = glob('./models/*.py')\n",
    "    for py in pyfiles:\n",
    "        copyfile(py, os.path.join(args.log_dir, 'codes') + \"/\" + py)\n",
    "    for py in modelfiles:\n",
    "        copyfile(py, os.path.join(args.log_dir, 'codes', py[2:]))\n",
    "\n",
    "formatted_print('Total Number of GPUs:', ngpus_per_node)\n",
    "formatted_print('Total Number of Workers:', args.workers)\n",
    "formatted_print('Batch Size:', args.batch_size)\n",
    "formatted_print('Max image Size:', args.img_size_max)\n",
    "formatted_print('Min image Size:', args.img_size_min)\n",
    "formatted_print('Log DIR:', args.log_dir)\n",
    "formatted_print('Result DIR:', args.res_dir)\n",
    "formatted_print('GAN TYPE:', args.gantype)\n",
    "\n",
    "if args.multiprocessing_distributed:\n",
    "    args.world_size = ngpus_per_node * args.world_size\n",
    "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
    "else:\n",
    "    generator = main_worker(args.gpu, ngpus_per_node, args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(stage, generator):\n",
    "  train_it = iter(data_loader)\n",
    "\n",
    "  x_in = next(train_it)\n",
    "\n",
    "  x_in = x_in.cuda( non_blocking=True)\n",
    "  x_org = x_in\n",
    "  \n",
    "  x_in = F.interpolate(x_in, (args.size_list[stage], args.size_list[stage]), mode='bilinear', align_corners=True)\n",
    "\n",
    "  x_in_list = []\n",
    "  print(len(args.size_list))\n",
    "  for xidx in range(0, stage + 1):\n",
    "      x_tmp = F.interpolate(x_org, (args.size_list[xidx], args.size_list[xidx]), mode='bilinear', align_corners=True)\n",
    "      x_tmp = F.pad(x_tmp, [5, 5, 5, 5], value=0)\n",
    "      x_in_list.append(x_tmp)\n",
    "  generator.eval()\n",
    "  out = generator(x_in_list)\n",
    "  return out\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
